{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from omegaconf import OmegaConf\n",
    "from model.model import KLLossMetricLearning, loss_different_class, loss_same_class, KL_d, KL_dreg\n",
    "from data_utils import cub2011\n",
    "from data_utils import stanford_cars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading stanford-car-dataset-by-classes-folder.zip to ./data/stanford-car-dataset-by-classes-folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.83G/1.83G [01:47<00:00, 18.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cars_trainset = stanford_cars.download_cars('./data', train=True, download=True, transforms=train_transform)\n",
    "# cars_testset = ImageFolder(DATA_DIR_TEST, transform = test_tfms)\n",
    "\n",
    "cub_trainset = cub2011.Cub2011('./data/cub2011', train=True, download=True)\n",
    "cub_testset = cub2011.Cub2011('./data/cub2011', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_trainloader = torch.utils.data.DataLoader(cars_trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "cars_testloader = torch.utils.data.DataLoader(cars_testset, batch_size=512,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_path = os.path.join(\"configs\", \"model.yaml\")\n",
    "conf = OmegaConf.load(conf_path)\n",
    "model = KLLossMetricLearning(**conf.get(\"model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.2365)\n",
      "tensor(6.1427)\n"
     ]
    }
   ],
   "source": [
    "images = torch.ones(64, 3, 32, 32)\n",
    "model(images)\n",
    "m1 = torch.tensor([[0.1, 0.3, 0.6], [0.5, 0, 0.5]])\n",
    "m2 = torch.tensor([[0.1, 0.3, 0.6], [0.5, 0, 0.5]])\n",
    "s1 = torch.tensor([[0.1, 0.3, 0.6], [0.5, 0, 0.5]])\n",
    "s2 = torch.tensor([[0.1, 0.3, 0.6], [0.5, 0, 0.5]])\n",
    "print(loss_same_class((m1, s1), (m2, s2), 0.5, 1))\n",
    "print(loss_different_class((m1, s1), (m2, s2), 0.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.7127,    inf])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5 * KL_dreg((m1.log(), s1), (m2.log(), s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.KLDivLoss(size_average=False)(m1.log(), s1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
